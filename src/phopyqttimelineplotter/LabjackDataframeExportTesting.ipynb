{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "# import cPickle\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# from PyQt5 import QtGui, QtWidgets\n",
    "# from PyQt5.QtWidgets import QMessageBox, QToolTip, QStackedWidget, QHBoxLayout, QVBoxLayout, QSplitter, QFormLayout, QLabel, QFrame, QPushButton, QTableWidget, QTableWidgetItem, QScrollArea\n",
    "# from PyQt5.QtWidgets import QApplication, QFileSystemModel, QTreeView, QWidget, QAction, qApp, QApplication, QTreeWidgetItem, QFileDialog \n",
    "# from PyQt5.QtGui import QPainter, QBrush, QPen, QColor, QFont, QIcon\n",
    "# from PyQt5.QtCore import Qt, QPoint, QRect, QObject, QEvent, pyqtSignal, pyqtSlot, QSize, QDir, QThreadPool\n",
    "\n",
    "# from phopyqttimelineplotter.GUI.UI.AbstractDatabaseAccessingWidgets import AbstractDatabaseAccessingQObject\n",
    "\n",
    "from phopyqttimelineplotter.app.filesystem.VideoUtils import findVideoFiles, VideoParsedResults, FoundVideoFileResult, CachedFileSource\n",
    "from phopyqttimelineplotter.app.filesystem.Workers.FileMetadataWorkers import FileMetadataWorker\n",
    "from phopyqttimelineplotter.app.filesystem.Workers.VideoFilesystemWorkers import VideoFilesystemWorker\n",
    "\n",
    "from phopyqttimelineplotter.GUI.Model.ModelViewContainer import ModelViewContainer\n",
    "from phopyqttimelineplotter.app.filesystem.FilesystemOperations import OperationTypes, PendingFilesystemOperation\n",
    "from phopyqttimelineplotter.app.filesystem.LabjackData.LabjackEventsLoader import LabjackEventsLoader, PhoServerFormatArgs\n",
    "\n",
    "from phopyqttimelineplotter.app.filesystem.FilesystemRecordBase import FilesystemRecordBase, FilesystemLabjackEvent_Record\n",
    "from phopyqttimelineplotter.GUI.Model.Events.PhoDurationEvent import PhoDurationEvent\n",
    "\n",
    "from phopyqttimelineplotter.app.filesystem.LabjackData.LabjackFilesystemLoadingMixin import LabjackEventFile, LabjackFilesystemLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Event Loading:\n",
    "\n",
    "## User-configurable settings:\n",
    "# should_filter_for_invalid_events = True\n",
    "should_filter_for_invalid_events = False\n",
    "aFoundLabjackDataFile = Path(\"I:/EventData/BB01/out_file_s470017560_20190911-20190820_46Combined.csv\")\n",
    "videoStartDates = []\n",
    "videoEndDates = []\n",
    "\n",
    "active_cache = dict()\n",
    "# LabjackEventFile: this serves as a container to hold the loaded events\n",
    "outEventFileObj = LabjackEventFile(aFoundLabjackDataFile)\n",
    "\n",
    "(dateTimes, labjackEventContainers, phoServerFormatArgs) = LabjackFilesystemLoader.loadLabjackEventsFile(aFoundLabjackDataFile, videoStartDates, videoEndDates, shouldLimitEventsToVideoDates=False, usePhoServerFormat=True, phoServerFormatIsStdOut=False, should_filter_for_invalid_events=should_filter_for_invalid_events)\n",
    "\n",
    "print('Loading complete... setting loaded values')\n",
    "# Cache the loaded values into the LabjackEventFile object.\n",
    "# outEventFileObj.set_loaded_values(dateTimes, [], [], labjackEventContainers, phoServerFormatArgs)\n",
    "outEventFileObj.set_loaded_values(dateTimes, [], [], labjackEventContainers, None)\n",
    "print('done updating cache...')\n",
    "\n",
    "if (not (aFoundLabjackDataFile in active_cache.keys())):\n",
    "    # print('Creating new cache entry for {}...'.format(str(aFoundLabjackDataFile)))\n",
    "    # Parent doesn't yet exist in cache\n",
    "    active_cache[aFoundLabjackDataFile] = outEventFileObj\n",
    "else:\n",
    "    # Parent already exists\n",
    "    print(\"WARNING: labjack file path {} already exists in the temporary cache. Updating its values...\".format(str(aFoundLabjackDataFile)))\n",
    "    active_cache[aFoundLabjackDataFile] = outEventFileObj\n",
    "    pass\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from file data\\output\\LabjackDataExport\\output_dataframe_1-9-2020_pandas_store.h5...\n",
      "done reading data\\output\\LabjackDataExport\\output_dataframe_1-9-2020_pandas_store.h5.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Import Dataframe from file:\n",
    "\"\"\"\n",
    "# dataframe_import_path = 'data/output/LabjackDataExport/output_dataframe_1-9-2020'\n",
    "out_dataframe_export_parent_path = Path('data/output/LabjackDataExport/')\n",
    "out_dataframe_export_path_basic = out_dataframe_export_parent_path.joinpath('output_dataframe_1-9-2020_basic_store.h5') # Used for basic objects\n",
    "out_dataframe_export_path_pandas = out_dataframe_export_parent_path.joinpath('output_dataframe_1-9-2020_pandas_store.h5') # Used for pandas Dataframe and Series objects\n",
    "        \n",
    "# # Basic\n",
    "# active_path = out_dataframe_export_path_basic\n",
    "# print('Reading data from file {}...'.format(str(active_path)))\n",
    "# active_store = pd.HDFStore(active_path)\n",
    "# print(active_store)\n",
    "# # in_df = active_store['variables_dataframe']\n",
    "# active_store.close()\n",
    "# print('done reading {}.'.format(str(active_path)))\n",
    "\n",
    "# Pandas:\n",
    "active_path = out_dataframe_export_path_pandas\n",
    "print('Reading data from file {}...'.format(str(active_path)))\n",
    "active_store = pd.HDFStore(active_path)\n",
    "# print(active_store)\n",
    "in_df = active_store['variables_dataframe']\n",
    "in_series = active_store['variables_series_of_dataframes']\n",
    "in_records_df = active_store['records_dataframe']\n",
    "\n",
    "active_store.close()\n",
    "print('done reading {}.'.format(str(active_path)))\n",
    "\n",
    "\n",
    "# in_df\n",
    "# for (aVariableIndex, aVariableData) in enumerate(variableData):\n",
    "#     aVariableData['']\n",
    "        \n",
    "#         print('Converting variableData to Pandas Dataframe...')\n",
    "#         out_df = get_variables_as_dataframe(variableData, active_labjack_variable_names)\n",
    "#         # out_df.to_json(orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_records_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_records_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_records_df.extended_info_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_records_df[['start_date', 'end_date', 'variable_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://stackoverflow.com/questions/38231591/splitting-dictionary-list-inside-a-pandas-column-into-separate-columns\n",
    "\n",
    "# in_records_df.extended_info_dict.apply(pd.Series)[['event_type', 'dispense_type', 'port']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_records_df.drop(['b'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose just the columns we care about. See https://stackoverflow.com/questions/11285613/selecting-multiple-columns-in-a-pandas-dataframe\n",
    "# https://stackoverflow.com/questions/38231591/splitting-dictionary-list-inside-a-pandas-column-into-separate-columns\n",
    "# https://stackoverflow.com/questions/34997174/how-to-convert-list-of-model-objects-to-pandas-dataframe/41762270\n",
    "\n",
    "# pd.concat([in_records_df.drop(['b'], axis=1), in_records_df['b'].apply(pd.Series)], axis=1)\n",
    "# final_out_df = pd.concat([in_records_df[['start_date', 'end_date', 'variable_name']], in_records_df.extended_info_dict.apply(pd.Series)[['event_type', 'dispense_type', 'port']]], axis=1)\n",
    "final_out_df = pd.concat([in_records_df[['start_date', 'variable_name']], in_records_df.extended_info_dict.apply(pd.Series)[['event_type', 'port']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_dataframe_export_path_final_csv = out_dataframe_export_parent_path.joinpath('output_final_dataframe_1-9-2020.csv') # Used for basic objects\n",
    "out_dataframe_export_path_final_csv = out_dataframe_export_parent_path.joinpath('output_final_dataframe_1-9-2020-Filtered.csv') # Used for basic objects\n",
    "\n",
    "final_out_df.to_csv(out_dataframe_export_path_final_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_series.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# str(in_series.Water1_BeamBreak.variableSpecificRecords)\n",
    "# get_extended_data()\n",
    "in_series.Water1_BeamBreak.variableSpecificRecords[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_series.Water1_BeamBreak.timestamps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_series.Water1_BeamBreak.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (recordIndex, aRecord) in in_series.Water1_BeamBreak.variableSpecificRecords:\n",
    "    print(aRecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(in_series, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(in_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(in_series, keys=['s1', 's2'],  names=['Series name', 'Row ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df = in_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df.variableSpecificRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# in_df.axes\n",
    "in_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
